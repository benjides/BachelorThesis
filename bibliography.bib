@misc{Silla2011,
abstract = {In this survey we discuss the task of hierarchical classification. The literature about this field is scattered across very different application domains and for that reason research in one domain is often done unaware of methods developed in other domains. We define what is the task of hierarchical classification and discuss why some related tasks should not be considered hierarchical classification. We also present a new perspective about some existing hierarchical classification approaches, and based on that perspective we propose a new unifying framework to classify the existing approaches. We also present a review of empirical comparisons of the existing methods reported in the literature as well as a conceptual comparison of those methods at a high level of abstraction, discussing their advantages and disadvantages.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.02293v1},
author = {Silla, Carlos N. and Freitas, Alex A.},
booktitle = {Data Mining and Knowledge Discovery},
doi = {10.1007/s10618-010-0175-9},
eprint = {arXiv:1507.02293v1},
isbn = {1384-5810},
issn = {13845810},
keywords = {DAG-structured class hierarchies,Hierarchical classification,Tree-structured class hierarchies},
pmid = {19477997},
title = {{A survey of hierarchical classification across different application domains}},
year = {2011}
}
@book{Suykens1996,
author = {Suykens, Johan A. K. and Vandewalle, Joos P. L. and {De Moor}, Bart L. R.},
booktitle = {Artificial Neural Networks for Modelling and Control of Non-Linear Systems},
doi = {10.1007/978-1-4757-2493-6},
title = {{Artificial Neural Networks for Modelling and Control of Non-Linear Systems}},
year = {1996}
}
@inproceedings{Mckay2004,
abstract = {This paper presents a system that extracts 109 musical features from symbolic recordings (MIDI, in this case) and uses them to classify the recordings by genre. The features used here are based on instrumentation, texture, rhythm, dynamics, pitch statistics, melody and chords. The classification is performed hierarchically using different sets of features at different levels of the hierarchy. Which features are used at each level, and their relative weightings, are determined using genetic algorithms. Classification is performed using a novel ensemble of feedforward neural networks and k-nearest neighbour classifiers. Arguments are presented emphasizing the importance of using high-level musical features, something that has been largely neglected in automatic classification systems to date in favour of low-level features. The effect on classification performance of varying the number of candidate features is examined in order to empirically demonstrate the importance of using a large variety of musically meaningful features. Two differently sized hierarchies are used in order to test the performance of the system under different conditions. Very encouraging classification success rates of 98{\%} for root genres and 90{\%} for leaf genres are obtained for a hierarchical taxonomy consisting of 9 leaf genres.},
author = {Mckay, Cory and Fujinaga, Ichiro},
booktitle = {5th International Conference on Music Information Retrieval – ISMIR 2004},
doi = {S0091-3057(99)00042-8 [pii]},
isbn = {84-88042-44-2},
keywords = {classification,features,genre,hierarchical,music},
pmid = {10418795},
title = {{Automatic Genre Classification Using Large High-Level Musical Feature Sets}},
year = {2004}
}
@article{Werbos1990,
abstract = {Basic backpropagation, which is a simple method now being widely$\backslash$nused in areas like pattern recognition and fault diagnosis, is reviewed.$\backslash$nThe basic equations for backpropagation through time, and applications$\backslash$nto areas like pattern recognition involving dynamic systems, systems$\backslash$nidentification, and control are discussed. Further extensions of this$\backslash$nmethod, to deal with systems other than neural networks, systems$\backslash$ninvolving simultaneous equations, or true recurrent networks, and other$\backslash$npractical issues arising with the method are described. Pseudocode is$\backslash$nprovided to clarify the algorithms. The chain rule for ordered$\backslash$nderivatives-the theorem which underlies backpropagation-is briefly$\backslash$ndiscussed. The focus is on designing a simpler version of$\backslash$nbackpropagation which can be translated into computer code and applied$\backslash$ndirectly by neutral network users},
author = {Werbos, Paul J.},
doi = {10.1109/5.58337},
issn = {15582256},
journal = {Proceedings of the IEEE},
title = {{Backpropagation Through Time: What It Does and How to Do It}},
year = {1990}
}
@inproceedings{Wang2016,
abstract = {While deep convolutional neural networks (CNNs) have shown a great success in single-label image classification, it is important to note that real world images generally contain multiple labels, which could correspond to different objects, scenes, actions and attributes in an image. Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results. These techniques, although working well, fail to explicitly exploit the label dependencies in an image. In this paper, we utilize recurrent neural networks (RNNs) to address this problem. Combined with CNNs, the proposed CNN-RNN framework learns a joint image-label embedding to characterize the semantic label dependency as well as the image-label relevance, and it can be trained end-to-end from scratch to integrate both information in a unified framework. Experimental results on public benchmark datasets demonstrate that the proposed architecture achieves better performance than the state-of-the-art multi-label classification model},
author = {Wang, Jiang and Yang, Yi and Mao, Junhua and Huang, Zhiheng and Huang, Chang and Xu, Wei},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.251},
isbn = {9781467388504},
issn = {10636919},
title = {{CNN-RNN: A Unified Framework for Multi-label Image Classification}},
year = {2016}
}
@inproceedings{Rajanna2016,
author = {Rajanna, Arjun Raj and Aryafar, Kamelia and Shokoufandeh, Ali and Ptucha, Raymond},
booktitle = {Proceedings - 2015 IEEE 14th International Conference on Machine Learning and Applications, ICMLA 2015},
doi = {10.1109/ICMLA.2015.160},
isbn = {9781509002870},
title = {{Deep neural networks: A case study for music genre classification}},
year = {2016}
}
@article{Srivastava2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Deep learning,Model combination,Neural networks,Regularization},
title = {{Dropout: A simple way to prevent neural networks from overfitting}},
year = {2014}
}
@book{EuropeanCommission2009,
author = {{European Commission}},
booktitle = {Luxembourg: Office for Official Publications of the {\ldots}},
doi = {10.2766/88064},
isbn = {9789279097287},
title = {{ECTS users' guide}},
year = {2009}
}
@inproceedings{Jensen2006,
author = {Jensen, Jesper H{\o}jvang and Christensen, Mads Gr{\ae}sb{\o}ll and Murthi, Manohar N. and Jensen, S{\o}ren Holdt},
booktitle = {European Signal Processing Conference},
issn = {22195491},
title = {{Evaluation of MFCC estimation techniques for music similarity}},
year = {2006}
}
@inproceedings{Li2011,
author = {Li, Tom L.H. and Chan, Antoni B.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-17832-0_30},
isbn = {3642178316},
issn = {03029743},
title = {{Genre classification and the invariance of MFCC features to key and tempo}},
year = {2011}
}
@article{InformationCommissionersOffice2018,
abstract = {The Guide to the GDPR explains the provisions of the GDPR to help organisations comply with its requirements. It is for those who have day-to-day responsibility for data protection. This is a living document and we are working to expand it in key areas. It includes links to relevant sections of the GDPR itself, to other ICO guidance and to guidance produced by the EU's Article 29 Working Party. The Working Party includes representatives of the data protection authorities from each EU member state, and the ICO is the UK's representative.},
archivePrefix = {arXiv},
arxivId = {Bird {\&} Bird. (2016). Guide to the General Data Protection Regulation, (April). Retrieved from http://www.twobirds.com/{\~{}}/media/pdfs/gdpr-pdfs/bird--bird--guide-to-the-general-data-protection-regulation.pdf?la=en},
author = {{Information Commissioner's Office}},
doi = {10.1111/j.1751-1097.1994.tb09662.x},
eprint = {/www.twobirds.com/{\~{}}/media/pdfs/gdpr-pdfs/bird--bird--guide-to-the-general-data-protection-regulation.pdf?la=en},
isbn = {1469-896X (Electronic)$\backslash$r0961-8368 (Linking)},
issn = {17511097},
journal = {Guide to the General Data Protection Regulation},
pmid = {15139834},
primaryClass = {Bird {\&} Bird. (2016). Guide to the General Data Protection Regulation, (April). Retrieved from http:},
title = {{Guide to the General Data Protection Regulation (GDPR)}},
year = {2018}
}
@article{Koller1997,
abstract = {The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies. One can use existing classifiers by ignoring the hierarchical structure treating the topics as separate classes. Unfortunately in the con text of text categorization we are faced with a large num ber of classes and a huge number of relevant features needed to distinguish between them. Consequently we are restricted to using only very simple classifiers both because of computational cost and the tendency of complex models to overfit. We propose an approach that utilizes the hierarchical topic structure to decompose the classification task in to a set of simpler problems one at each node in the classification tree. As we show each of these smaller problems can be solved accurately by focusing only on a very small set of features those relevant to the task at hand. This set of relevant features varies widely throughout the hierarchy so that while the overall relevant feature set may be large each classifier only examines a small subset. The use of reduced feature sets allows us to utilize more complex probabilistic models without encoun tering the computational and robustness difficulties described above.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Koller, Daphne and Sahami, Mehran},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
isbn = {1558604863},
issn = {13514180},
journal = {International Conference on Machine Learning},
keywords = {author,cs,edu,email address of contact,feature selec-,hierarchical classi cation,information retrieval,probabilistic models,sahami,stanford,tion},
pmid = {15991970},
title = {{Hierarchically Classifying Documents Using Very Few Words}},
year = {1997}
}
@inproceedings{Grodzicki2008a,
abstract = {This paper considers the multilabel classification problem, which$\backslash$nis a generalization of traditional two-class or multi-class classification$\backslash$nproblem. In multilabel classification a set of labels (categories)$\backslash$nis given and each training instance is associated with a subset of$\backslash$nthis label-set. The task is to output the appropriate subset of labels$\backslash$n(generally of unknown size) for a given, unknown testing instance.$\backslash$nSome improvements to the existing neural network multilabel classification$\backslash$nalgorithm, named BP-MLL, are proposed here. The modifications concern$\backslash$nthe form of the global error function used in BP-MLL. The modified$\backslash$nclassification system is tested in the domain of functional genomics,$\backslash$non the yeast genome data set. Experimental results show that proposed$\backslash$nmodifications visibly improve the performance of the neural network$\backslash$nbased multilabel classifier. The results are statistically significant.$\backslash$n漏 2008 Springer-Verlag Berlin Heidelberg.},
author = {Grodzicki, Rafa{\l} and Ma{\'{n}}dziuk, Jacek and Wang, Lipo},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-87700-4_41},
isbn = {3540876995},
issn = {03029743},
keywords = {Backpropagation,Bioinformatics,Functional genomics,Learning system,Multilabel,Neural network},
title = {{Improved multilabel classification with neural networks}},
year = {2008}
}
@inproceedings{Grodzicki2008,
abstract = {This paper considers the multilabel classification problem, which is a generalization of traditional two-class or multi-class classification problem. In multilabel classification a set of labels (categories) is given and each training instance is associated with a subset of this label-set. The task is to output the appropriate subset of labels (generally of unknown size) for a given, unknown testing instance. Some improvements to the existing neural network multilabel classification algorithm, named BP-MLL, are proposed here. The modifications concern the form of the global error function used in BP-MLL. The modified classification system is tested in the domain of functional genomics, on the yeast genome data set. Experimental results show that proposed modifications visibly improve the performance of the neural network based multilabel classifier. The results are statistically significant. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Grodzicki, Rafa{\l} and Ma{\'{n}}dziuk, Jacek and Wang, Lipo},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-87700-4_41},
isbn = {3540876995},
issn = {03029743},
keywords = {Backpropagation,Bioinformatics,Functional genomics,Learning system,Multilabel,Neural network},
title = {{Improved multilabel classification with neural networks}},
year = {2008}
}
@article{Charte2015,
abstract = {Learning from imbalanced data is a problem which arises in many real-world scenarios, so does the need to build classifiers able to predict more than one class label simultaneously (multilabel classification). Dealing with imbalance by means of resampling methods is an approach that has been deeply studied lately, primarily in the context of traditional (non-multilabel) classification. In this paper the process of synthetic instance generation for multilabel datasets (MLDs) is studied and MLSMOTE (Multilabel Synthetic Minority Over-sampling Technique), a new algorithm aimed to produce synthetic instances for imbalanced MLDs, is proposed. An extensive review on how imbalance in the multilabel context has been tackled in the past is provided, along with a thorough experimental study aimed to verify the benefits of the proposed algorithm. Several multilabel classification algorithms and other multilabel oversampling methods are considered, as well as ensemble-based algorithms for imbalanced multilabel classification. The empirical analysis shows that MLSMOTE is able to improve the classification results produced by existent proposals.},
author = {Charte, Francisco and Rivera, Antonio J. and {Del Jesus}, Mar{\'{i}}a J. and Herrera, Francisco},
doi = {10.1016/j.knosys.2015.07.019},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Imbalanced learning,Multilabel classification,Oversampling,Synthetic instance generation},
title = {{MLSMOTE: Approaching imbalanced multilabel learning through synthetic instance generation}},
year = {2015}
}
@article{Gibaja2014,
author = {Gibaja, Eva and Ventura, Sebastian},
doi = {10.1002/widm.1139},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
month = {may},
title = {{Multilabel Learning: A Review of the State of The Art and Ongoing Research}},
year = {2014}
}
@article{Zhang2006,
abstract = {In multi-label learning, each instance in the training set is associated with a set of labels, and the task is to output a label set whose size is unknown a priori for each unseen instance. In this paper, this problem is addressed in the way that a neural network algorithm named BP-MLL, i.e. Backpropagation for Multi-Label Learning, is proposed. It is derived from the popular Backpropagation algorithm through employing a novel error function capturing the characteristics of multi-label learning, i.e. the labels belonging to an instance should be ranked higher than those not belonging to that instance. Applications to two real- world multi-label learning problems, i.e. functional genomics and text categorization, show that the performance of BP-MLL is superior to those of some well-established multi-label learning algorithms.},
archivePrefix = {arXiv},
arxivId = {1683770},
author = {Zhang, Min Ling and Zhou, Zhi Hua},
doi = {10.1109/TKDE.2006.162},
eprint = {1683770},
isbn = {8422673517},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Backpropagation,Data mining,Functional genomics,Machine learning,Multilabel learning,Neural networks,Text categorization},
title = {{Multilabel neural networks with applications to functional genomics and text categorization}},
year = {2006}
}
@article{Zhang2006a,
abstract = {In multi-label learning, each instance in the training set is associated with a set of labels, and the task is to output a label set whose size is unknown a priori for each unseen instance. In this paper, this problem is addressed in the way that a neural network algorithm named BP-MLL, i.e. Backpropagation for Multi-Label Learning, is proposed. It is derived from the popular Backpropagation algorithm through employing a novel error function capturing the characteristics of multi-label learning, i.e. the labels belonging to an instance should be ranked higher than those not belonging to that instance. Applications to two real- world multi-label learning problems, i.e. functional genomics and text categorization, show that the performance of BP-MLL is superior to those of some well-established multi-label learning algorithms.},
author = {Zhang, Min Ling and Zhou, Zhi Hua},
doi = {10.1109/TKDE.2006.162},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Backpropagation,Data mining,Functional genomics,Machine learning,Multilabel learning,Neural networks,Text categorization},
title = {{Multilabel neural networks with applications to functional genomics and text categorization}},
year = {2006}
}
@inproceedings{Flach2015,
abstract = {Precision-Recall analysis abounds in applications of binary classification where true negatives do not add value and hence should not affect assessment of the classifier's performance. Perhaps inspired by the many advantages of receiver operating characteristic (ROC) curves and the area under such curves for accuracybased performance assessment, many researchers have taken to report Precision-Recall (PR) curves and associated areas as performance metric. We demonstrate in this paper that this practice is fraught with difficulties, mainly because of incoherent scale assumptions-e.g., the area under a PR curve takes the arithmetic mean of precision values whereas the F$\beta$ score applies the harmonic mean. We show how to fix this by plotting PR curves in a different coordinate system, and demonstrate that the new Precision-Recall-Gain curves inherit all key advantages of ROC curves. In particular, the area under Precision-Recall-Gain curves conveys an expected F1 score on a harmonic scale, and the convex hull of a Precision-Recall-Gain curve allows us to calibrate the classifier's scores so as to determine, for each operating point on the convex hull, the interval of $\beta$ values for which the point optimises F$\beta$. We demonstrate experimentally that the area under traditional PR curves can easily favour models with lower expected F1 score than others, and so the use of Precision-Recall-Gain curves will result in better model selection.},
author = {Flach, Peter A. and Kull, Meelis},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
title = {{Precision-Recall-Gain curves: PR analysis done right}},
year = {2015}
}
@article{OrganizacionMundialdelaPropiedadIntelectual-OMPI-2016,
abstract = {Este folleto viene a ser una introducci{\'{o}}n destinada a no especialistas y personas no familiarizadas con la propiedad industrial. En {\'{e}}l se explican en t{\'{e}}rminos llanos los principios en los que se basan los derechos de propiedad industrial. Se describen, por consiguiente, las formas m{\'{a}}s comunes que adopta la propiedad industrial, a saber, las patentes y los modelos de utilidad en relaci{\'{o}}n con las invenciones, los dise{\~{n}}os industriales, las marcas y las indicaciones geogr{\'{a}}ficas y se explican los medios que ofrece el sistema de propiedad industrial a los creadores para proteger sus creaciones. En el folleto no se ofrece orientaci{\'{o}}n jur{\'{i}}dica ni administrativa detallada, por ejemplo, sobre la forma de solicitar protecci{\'{o}}n o de proceder ante una infracci{\'{o}}n de derechos de propiedad industrial, por cuanto esa informaci{\'{o}}n puede solicitarse en las oficinas nacionales de propiedad intelectual. En la contraportada del folleto se ofrece informaci{\'{o}}n sobre sitios Web y publicaciones de utilidad para todo lector que desee profundizar en la materia. En cuanto al derecho de autor, cabe remitirse a una publicaci{\'{o}}n similar de la OMPI, a saber, "Principios b{\'{a}}sicos del derecho de autor y los derechos conexos"},
author = {{Organizaci{\'{o}}n Mundial de la Propiedad Intelectual -OMPI-}},
isbn = {978-92-805-1615-9},
journal = {Organizacion Mundial de la Propiedad Intelectual},
title = {{Principios B{\'{a}}sicos de la Propiedad Industrial}},
year = {2016}
}
@article{Tsoumakas2011,
abstract = {A simple yet effective multilabel learning method, called label powerset (LP), considers each distinct combination of labels that exist in the training set as a different class value of a single-label classification task. The computational efficiency and predictive performance of LP is challenged by application domains with large number of labels and training examples. In these cases, the number of classes may become very large and at the same time many classes are associated with very few training examples. To deal with these problems, this paper proposes breaking the initial set of labels into a number of small random subsets, called labelsets and employing LP to train a corresponding classifier. The labelsets can be either disjoint or overlapping depending on which of two strategies is used to construct them. The proposed method is called {\{}$\backslash$rm RA{\}}k{\{}$\backslash$rm EL{\}} (RAndom k labELsets), where k is a parameter that specifies the size of the subsets. Empirical evidence indicates that {\{}$\backslash$rm RA{\}}k{\{}$\backslash$rm EL{\}} manages to improve substantially over LP, especially in domains with large number of labels and exhibits competitive performance against other high-performing multilabel learning methods.},
author = {Tsoumakas, Grigorios and Katakis, Ioannis and Vlahavas, Ioannis},
doi = {10.1109/TKDE.2010.164},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Categorization,classification,ensembles,labelset,multilabel},
pmid = {6256800},
title = {{Random k-labelsets for multilabel classification}},
year = {2011}
}
@article{Rodriguez2010,
abstract = {In the machine learning field, the performance of a classifier is usually measured in terms of prediction error. In most real-world problems, the error cannot be exactly calculated and it must be estimated. Therefore, it is important to choose an appropriate estimator of the error. This paper analyzes the statistical properties, bias and variance, of the kappa-fold cross-validation classification error estimator (k-cv). Our main contribution is a novel theoretical decomposition of the variance of the kappa-cv considering its sources of variance: sensitivity to changes in the training set and sensitivity to changes in the folds. The paper also compares the bias and variance of the estimator for different values of kappa. The experimental study has been performed in artificial domains because they allow the exact computation of the implied quantities and we can rigorously specify the conditions of experimentation. The experimentation has been performed for two classifiers (naive Bayes and nearest neighbor), different numbers of folds, sample sizes, and training sets coming from assorted probability distributions. We conclude by including some practical recommendation on the use of kappa-fold cross validation.},
author = {Rodr{\'{i}}guez, Juan Diego and P{\'{e}}rez, Aritz and Lozano, Jose Antonio},
doi = {10.1109/TPAMI.2009.187},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {bias and variance,decomposition of the variance,error estimation,k-fold cross validation,prediction error,sources of sensitivity,supervised classification},
title = {{Sensitivity Analysis of k-Fold Cross Validation in Prediction Error Estimation}},
year = {2010}
}
@article{Blagus2013,
author = {Blagus, Rok and Lusa, Lara},
doi = {10.1186/1471-2105-14-106},
issn = {14712105},
journal = {BMC Bioinformatics},
title = {{SMOTE for high-dimensional class-imbalanced data}},
year = {2013}
}
@article{Chawla2002,
author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
title = {{SMOTE: Synthetic minority over-sampling technique}},
year = {2002}
}
@article{Bostrom2011,
abstract = {Frankish (Cambridge University Press, 2011): forthcoming The possibility of creating thinking machines raises a host of ethical issues. These questions relate both to ensuring that such machines do not harm humans and other morally relevant beings, and to the moral status of the machines themselves. The first section discusses issues that may arise in the near future of AI. The second section outlines challenges for ensuring that AI operates safely as it approaches humans in its intelligence. The third section outlines how we might assess whether, and in what circumstances, AIs themselves have moral status. In the fourth section, we consider how AIs might differ from humans in certain basic respects relevant to our ethical assessment of them. The final section addresses the issues of creating AIs more intelligent than human, and ensuring that they use their advanced intelligence for good rather than ill. Ethics in Machine Learning and Other Domain-Specific AI Algorithms Imagine, in the near future, a bank using a machine learning algorithm to recommend mortgage applications for approval. A rejected applicant brings a lawsuit against the bank, alleging that the algorithm is discriminating racially against mortgage applicants. The bank replies that this is impossible, since the algorithm is deliberately blinded to the race of the applicants. Indeed, that was part of the bank's rationale for implementing the system. Even so, statistics show that the bank's approval rate for black applicants has been steadily dropping. Submitting ten apparently equally qualified genuine applicants (as determined by a separate panel of human judges) shows that the algorithm accepts white applicants and rejects black applicants. What could possibly be happening? Finding an answer may not be easy. If the machine learning algorithm is based on a complicated neural network, or a genetic algorithm produced by directed evolution, then it may prove nearly impossible to understand why, or even how, the algorithm is judging applicants based on their race. On the other hand, a machine learner based on decision trees or Bayesian networks is much more transparent to programmer},
author = {Bostrom, Nick and Yudkowsky, Eliezer},
doi = {10.1017/CBO9781139046855.020},
isbn = {978-0521871426},
issn = {13573039},
journal = {Cambridge University Press},
keywords = {artificial intelligence,ethics},
pmid = {14748188},
title = {{THE ETHICS OF ARTIFICIAL INTELLIGENCE (2011) Nick Bostrom Eliezer Yudkowsky Draft for Cambridge Handbook of Artificial Intelligence, eds}},
year = {2011}
}
@inproceedings{Bogdanov2018,
author = {Bogdanov, Dmitry and Porter, Alastair and Urbano, Juli{\'{a}}n and Schreiber, Hendrik},
booktitle = {CEUR Workshop Proceedings},
issn = {16130073},
title = {{The MediaEval 2018 AcousticBrainz Genre Task: Content-based music genre recognition from multiple sources}},
year = {2018}
}

@misc{cs231n,
    title = {Neural Networks},
    howpublished = "\url{http://cs231n.github.io/neural-networks-1/}"
}


@misc{pythonabout,
    title = {About Python},
    howpublished = "\url{https://www.python.org/doc/essays/blurb/}"
}

@misc{pandas,
  title = {pandas},
  howpublished = "\url{https://pandas.pydata.org/}",
}

@misc{numpy,
    title = {NumpPy},
    howpublished = "\url{https://numpy.org/}",
}

@misc{scikit,
    title = {scikit-learn},
    howpublished = "\url{https://scikit-learn.org/}",
}

@misc{matplotlib,
    title = {Matplotlib},
    howpublished = "\url{https://matplotlib.org/}",
}

@misc{seaborn,
    title = {seaborn},
    howpublished = "\url{https://seaborn.pydata.org/}",
}

@misc{mongo,
    title = {MongoDB},
    howpublished = "\url{https://www.mongodb.com/}",
}

@misc{json,
    title = {JSON},
    howpublished = "\url{https://www.json.org/}",
}

@misc{tensorflow,
    title = {TensorFlow},
    howpublished = "\url{https://www.tensorflow.org/}",
}

@misc{keras,
    title = {Keras},
    howpublished = "\url{https://keras.io/}"
}


@misc{essentia,
    title = {Essentia},
    howpublished = "\url{https://essentia.upf.edu/}"
}


@misc{mathann,
    title = {Intro to optimization in deep learning: Gradient Descent},
    howpublished = "\url{https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/}"
}

@misc{tesla,
    title = {Tesla hit with another lawsuit over a fatal Autopilot crash},
    howpublished = "\url{https://www.theverge.com/2019/8/1/20750715/tesla-autopilot-crash-lawsuit-wrongful-death}"
}

@misc{opensource,
    title = {Basics of Open Source},
    howpublished = "\url{https://opensource.org/faq}"
}

@misc{opensourcedef,
    title = {The Open Source Definition},
    howpublished = "\url{https://opensource.org/osd}"
}